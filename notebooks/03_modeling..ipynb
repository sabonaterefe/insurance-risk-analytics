{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbad027-0022-46ad-9ef9-343ee4719f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded data: 618,176 rows\n",
      "üîç Valid claim records: 2,641\n",
      "\n",
      "üìç Running Claim Severity Model...\n",
      "\n",
      "üìä Severity Model ‚Äî RMSE: 1358.45, R¬≤: 0.9981\n",
      "\n",
      "üìç Running Claim Probability Model...\n",
      "\n",
      "üìä Claim Probability Model ‚Äî AUC: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    153884\n",
      "           1       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           1.00    154544\n",
      "   macro avg       1.00      1.00      1.00    154544\n",
      "weighted avg       1.00      1.00      1.00    154544\n",
      "\n",
      "\n",
      "üìç Running Premium Prediction Model...\n",
      "\n",
      "üìä Premium Model ‚Äî RMSE: 35.05, R¬≤: 0.9721\n",
      "\n",
      "üîé SHAP Summary ‚Äî Severity Model\n",
      "\n",
      "üß† Top SHAP Features:\n",
      "  ‚Ä¢ margin: 24851.8633\n",
      "  ‚Ä¢ suminsured: 285.7473\n",
      "  ‚Ä¢ loss_ratio: 193.8185\n",
      "  ‚Ä¢ totalpremium: 143.3830\n",
      "  ‚Ä¢ customvalueestimate: 100.3822\n",
      "  ‚Ä¢ numberofdoors: 83.8465\n",
      "  ‚Ä¢ calculatedpremiumperterm: 77.2729\n",
      "  ‚Ä¢ registrationyear: 59.7718\n",
      "  ‚Ä¢ underwrittencoverid: 56.3280\n",
      "  ‚Ä¢ postalcode: 47.7493\n",
      "\n",
      "‚úÖ Task 4 Complete ‚Äî Results printed and SHAP summary saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def ensure_directories():\n",
    "    os.makedirs(\"reports/figures\", exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    df = dd.read_parquet(\"../data/processed/insurance_data_with_features.parquet\")\n",
    "    df = df[df[\"totalpremium\"] > 0].compute()  # Load necessary rows and convert to DataFrame\n",
    "    \n",
    "    df = drop_empty_columns(df)  # Drop columns with all missing values\n",
    "    df = optimize_dataframe(df)\n",
    "    \n",
    "    df[\"has_claim\"] = (df[\"totalclaims\"] > 0).astype(int)\n",
    "    df[\"loss_ratio\"] = df[\"totalclaims\"] / df[\"totalpremium\"]\n",
    "    df[\"margin\"] = df[\"totalpremium\"] - df[\"totalclaims\"]\n",
    "    \n",
    "    print(f\"‚úÖ Loaded data: {df.shape[0]:,} rows\")\n",
    "    print(f\"üîç Valid claim records: {(df['has_claim'] == 1).sum():,}\")\n",
    "    return df\n",
    "\n",
    "def optimize_dataframe(df):\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    for col in df.select_dtypes(include=['int64']).columns:\n",
    "        df[col] = df[col].astype('int32')\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "def drop_empty_columns(df):\n",
    "    return df.dropna(axis=1, how='all')  # Drop columns with all missing values\n",
    "\n",
    "def encode_features(df, exclude=[]):\n",
    "    return df.drop(columns=exclude, errors=\"ignore\")\n",
    "\n",
    "def run_severity_model(df):\n",
    "    df_sev = df[df[\"has_claim\"] == 1].copy()\n",
    "    if df_sev.shape[0] < 20:\n",
    "        print(\"‚ö†Ô∏è Not enough data for severity modeling.\")\n",
    "        return None, None\n",
    "\n",
    "    X = encode_features(df_sev, exclude=[\"totalclaims\"])\n",
    "    y = df_sev[\"totalclaims\"]\n",
    "    X = X.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    model = xgb.XGBRegressor(tree_method=\"hist\", random_state=42)\n",
    "    pipeline = Pipeline(steps=[('imputer', imputer), ('regressor', model)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f\"\\nüìä Severity Model ‚Äî RMSE: {rmse:.2f}, R¬≤: {r2:.4f}\")\n",
    "    return pipeline, X_train\n",
    "\n",
    "def run_premium_model(df):\n",
    "    df = drop_empty_columns(df)  # Drop columns with all missing values\n",
    "    X = encode_features(df, exclude=[\"totalpremium\"])\n",
    "    y = df[\"totalpremium\"]\n",
    "    X = X.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    model = RandomForestRegressor(max_depth=12, n_estimators=100, random_state=42)\n",
    "    pipeline = Pipeline(steps=[('imputer', imputer), ('regressor', model)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f\"\\nüìä Premium Model ‚Äî RMSE: {rmse:.2f}, R¬≤: {r2:.4f}\")\n",
    "\n",
    "def run_claim_probability_model(df):\n",
    "    df = drop_empty_columns(df)  # Drop columns with all missing values\n",
    "    X = encode_features(df, exclude=[\"has_claim\"])\n",
    "    y = df[\"has_claim\"]\n",
    "    X = X.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    pipeline = Pipeline(steps=[('imputer', imputer), ('classifier', model)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\nüìä Claim Probability Model ‚Äî AUC: {roc_auc_score(y_test, proba):.4f}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "def explain_shap(pipeline, X_train):\n",
    "    try:\n",
    "        # Extract the model from the pipeline\n",
    "        model = pipeline.named_steps['regressor']\n",
    "        \n",
    "        print(\"\\nüîé SHAP Summary ‚Äî Severity Model\")\n",
    "        explainer = shap.Explainer(model)\n",
    "        shap_values = explainer(X_train)\n",
    "        \n",
    "        # Convert SHAP values to DataFrame for analysis\n",
    "        shap_df = pd.DataFrame(shap_values.values, columns=X_train.columns)\n",
    "\n",
    "        # Calculate mean absolute SHAP values for feature importance\n",
    "        feature_importance = np.abs(shap_df).mean(axis=0).sort_values(ascending=False)\n",
    "\n",
    "        # Plot SHAP summary\n",
    "        shap.summary_plot(shap_values, X_train, show=False)\n",
    "        plt.title(\"SHAP Summary ‚Äî Claim Severity\")\n",
    "        plt.savefig(\"reports/figures/severity_shap_summary.png\")\n",
    "        plt.close()\n",
    "\n",
    "        print(\"\\nüß† Top SHAP Features:\")\n",
    "        for feat, val in feature_importance.head(10).items():\n",
    "            print(f\"  ‚Ä¢ {feat}: {val:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SHAP explanation failed: {e}\")\n",
    "\n",
    "def main():\n",
    "    ensure_directories()\n",
    "    df = load_data()\n",
    "\n",
    "    print(\"\\nüìç Running Claim Severity Model...\")\n",
    "    sev_model, X_train = run_severity_model(df)\n",
    "\n",
    "    print(\"\\nüìç Running Claim Probability Model...\")\n",
    "    run_claim_probability_model(df)\n",
    "\n",
    "    print(\"\\nüìç Running Premium Prediction Model...\")\n",
    "    run_premium_model(df)\n",
    "\n",
    "    if sev_model and X_train is not None:\n",
    "        explain_shap(sev_model, X_train)  # Passing the pipeline directly\n",
    "\n",
    "    print(\"\\n‚úÖ Task 4 Complete ‚Äî Results printed and SHAP summary saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b894894-df89-4325-b111-652befdee0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
